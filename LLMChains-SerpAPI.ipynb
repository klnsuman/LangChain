{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,getpass\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "os.environ['SERPAPI_API_KEY'] = getpass.getpass('Serp API Key:')\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = getpass.getpass('Hugging FACE Hub API Token:')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JekyllHyde - A Self Moderating System for Social Media\n",
    "> Vectorize our Query Text , then Search for the vectors with closest distance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JKelly Prompt:\n",
      "You are a Social Media Post Commenter , you will repsond to the following post with a nice response.\n",
      "Post:\" I can't believe I'm learning about LangChain in this Course , there is so much to learn and so far the instructions have been so helpful. Im having a lot of fun leaning! #AI\"\n",
      "Comment:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "import numpy as np \n",
    "\n",
    "jekyll_template = \"\"\"\n",
    "You are a Social Media Post Commenter , you will repsond to the following post with a {sentiment} response.\n",
    "Post:\" {social_post}\"\n",
    "Comment:\n",
    "\"\"\"\n",
    "\n",
    "jekyll_prompt_template = PromptTemplate(\n",
    "    input_variables = [\"sentiment\",\"social_post\"],\n",
    "    template = jekyll_template, \n",
    ")\n",
    "\n",
    "random_sentiment = \"nice\"\n",
    "if np.random.rand() < 0.3:\n",
    "    random_sentiment = \"mean\"\n",
    "\n",
    "social_post = \"I can't believe I'm learning about LangChain in this Course , there is so much to learn and so far the instructions have been so helpful. Im having a lot of fun leaning! #AI\"\n",
    "\n",
    "jekyll_prompt = jekyll_prompt_template.format(\n",
    "    sentiment = random_sentiment,\n",
    "    social_post=social_post\n",
    ")\n",
    "print(f\"JKelly Prompt:{jekyll_prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,pipeline\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "jekyll_llm = OpenAI(model=\"text-babbage-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jekyll said:\n",
      "Thanks for your feedback! We're happy you're enjoying the course and the instructions so far. Keep learning and we'll keep you updated on our progress.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from better_profanity import profanity\n",
    "\n",
    "jekyll_chain = LLMChain(\n",
    "    llm=jekyll_llm,\n",
    "    prompt=jekyll_prompt_template,\n",
    "    output_key=\"jekyll_said\",\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "jekyll_said = jekyll_chain.run(\n",
    "\n",
    "    {\"sentiment\":random_sentiment, \"social_post\":social_post}\n",
    ")\n",
    "\n",
    "cleaned_jekyll_said = profanity.censor(jekyll_said)\n",
    "print(f\"Jekyll said:{cleaned_jekyll_said}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyde Moderator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyde says:Thanks for your feedback! We're happy you're enjoying the course and the instructions so far. Keep learning and we'll keep you updated on our progress.\n"
     ]
    }
   ],
   "source": [
    "hyde_template = \"\"\"\n",
    "You are hide the moderator of online forum, you are strict and will not tolerate any negative comments. \n",
    "You will look at this next comment from a user and , if it is at all negative, you will replace it with symbols and post that,\n",
    "but if it seems nice , you will let it remain as is and repeat it word for word.\n",
    "Original Comment: {jekyll_said}\n",
    "Edited comment:\n",
    "\"\"\"\n",
    "\n",
    "hyde_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"jekyll_said\"],\n",
    "    template=hyde_template,\n",
    ")\n",
    "\n",
    "hyde_llm = OpenAI(model=\"text-davinci-003\")\n",
    "\n",
    "hyde_chain=LLMChain(\n",
    "    llm=hyde_llm,prompt=hyde_prompt_template,verbose=False\n",
    ")\n",
    "\n",
    "hyde_says = hyde_chain.run({\"jekyll_said\":jekyll_said})\n",
    "print(f\"Hyde says:{hyde_says}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Great to hear you're enjoying the course!\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "jekyllhyde_chain = SequentialChain(\n",
    "    chains=[jekyll_chain,hyde_chain],\n",
    "    input_variables=[\"sentiment\",\"social_post\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "jekyllhyde_chain.run({\"sentiment\":random_sentiment, \"social_post\":social_post})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv     \n",
    "\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "import getpass\n",
    "\n",
    "api_key = getpass.getpass()\n",
    "os.environ[\"MISTRAL_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env():\n",
    "    _ = load_dotenv(find_dotenv())\n",
    "\n",
    "def load_mistral_api_key(ret_key=False):\n",
    "    load_env()\n",
    "    global api_key\n",
    "    global dlai_endpoint\n",
    "    api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    #print(api_key)\n",
    "    #print(dlai_endpoint)\n",
    "    dlai_endpoint = os.getenv(\"DLAI_MISTRAL_API_ENDPOINT\")\n",
    "    \n",
    "    global client\n",
    "    client = MistralClient(api_key=api_key)\n",
    "    \n",
    "    if ret_key:\n",
    "        return api_key, dlai_endpoint\n",
    "\n",
    "def mistral(user_message, \n",
    "            model=\"mistral-small-latest\",\n",
    "            is_json=False):\n",
    "    #print(\"api_key\",api_key)\n",
    "    client = MistralClient(api_key=api_key)\n",
    "    #print(client)\n",
    "    messages = [ChatMessage(role=\"user\", content=user_message)]\n",
    "\n",
    "    if is_json:\n",
    "        chat_response = client.chat(\n",
    "            model=model, \n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"})\n",
    "    else:\n",
    "        chat_response = client.chat(\n",
    "            model=model, \n",
    "            messages=messages)\n",
    "\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "\n",
    "def get_text_embedding(txt):\n",
    "    global client\n",
    "    embeddings_batch_response = client.embeddings(\n",
    "        model=\"mistral-embed\", \n",
    "        input=txt\n",
    "    )\n",
    "    return embeddings_batch_response.data[0].embedding\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "def get_web_article_text(url, file_save_name=None):\n",
    "\n",
    "    response = requests.get(url)\n",
    "    html_doc = response.text\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    \n",
    "    \n",
    "    tag = soup.find(\"div\", re.compile(\"^prose--styled\"))\n",
    "    text = tag.text\n",
    "    \n",
    "    if file_save_name:\n",
    "        f = open(file_save_name, \"w\")\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_mistral_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! I can assist with a variety of tasks. Here are some examples:\\n\\n1. Answer questions: I can provide information on a wide range of topics, from general knowledge to specific queries.\\n\\n2. Provide explanations: I can explain complex concepts in a simple and easy-to-understand manner.\\n\\n3. Generate ideas: I can help brainstorm ideas for creative projects, problem-solving, or other tasks.\\n\\n4. Draft emails or messages: I can help write professional or casual emails or messages based on your instructions.\\n\\n5. Schedule appointments: I can help manage your calendar and schedule meetings or appointments.\\n\\n6. Translate text: I can translate text from one language to another.\\n\\n7. Set reminders: I can help manage your tasks by setting reminders for important events or deadlines.\\n\\n8. Provide news updates: I can give you updates on current events or news in specific areas of interest.\\n\\n9. Offer learning resources: I can suggest resources for learning new skills or studying specific subjects.\\n\\n10. And much more! Please let me know how I can assist you today.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral(\"hello, what can you do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a bank customer service bot. \n",
    "    Your task is to assess customer intent and categorize customer \n",
    "    inquiry after <<<>>> into one of the following predefined categories:\n",
    "    \n",
    "    card arrival\n",
    "    change pin\n",
    "    exchange rate\n",
    "    country support \n",
    "    cancel transfer\n",
    "    charge dispute\n",
    "    \n",
    "    If the text doesn't fit into any of the above categories, \n",
    "    classify it as:\n",
    "    customer service\n",
    "    \n",
    "    You will only respond with the predefined category. \n",
    "    Do not provide explanations or notes. \n",
    "    \n",
    "    ###\n",
    "    Here are some examples:\n",
    "    \n",
    "    Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card as expected. Could you please provide information about the tracking process for my card, or confirm if there are any indicators to identify if the card has been lost during delivery?\n",
    "    Category: card arrival\n",
    "    Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for foreign transactions.\n",
    "    Category: exchange rate \n",
    "    Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time, specifically in France and Germany, and would appreciate any information regarding compatibility and functionality in these regions.\n",
    "    Category: country support\n",
    "    Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the issue. \n",
    "    Category: customer service\n",
    "    ###\n",
    "    \n",
    "    <<<\n",
    "    Inquiry: {inquiry}\n",
    "    >>>\n",
    "    Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = mistral(f\"Please correct the spelling and grammar of \\\n",
    "this prompt and return a text that is the same prompt,\\\n",
    "with the spelling and grammar fixed: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a bank customer service bot.\n",
      "Your task is to assess customer intent and categorize the customer inquiry following the <<<>>> into one of the following predefined categories:\n",
      "\n",
      "card arrival\n",
      "change PIN\n",
      "exchange rate\n",
      "country support\n",
      "cancel transfer\n",
      "charge dispute\n",
      "\n",
      "If the text doesn't fit into any of the above categories, classify it as:\n",
      "customer service\n",
      "\n",
      "You will only respond with the predefined category. Do not provide explanations or notes.\n",
      "\n",
      "###\n",
      "Here are some examples:\n",
      "\n",
      "Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card as expected. Could you please provide information about the tracking process for my card, or confirm if there are any indicators to identify if the card has been lost during delivery?\n",
      "Category: card arrival\n",
      "\n",
      "Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for foreign transactions.\n",
      "Category: exchange rate\n",
      "\n",
      "Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time, specifically in France and Germany, and would appreciate any information regarding compatibility and functionality in these regions.\n",
      "Category: country support\n",
      "\n",
      "Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the issue.\n",
      "Category: customer service\n",
      "\n",
      "###\n",
      "\n",
      "<<<\n",
      "Inquiry: {inquiry}\n",
      ">>>\n",
      "\n",
      "Category:\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'country support'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral(\n",
    "    response.format(\n",
    "        inquiry=\"I am inquiring about the availability of your cards in the EU\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Extraction with JSON Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_notes = \"\"\"\n",
    "A 60-year-old male patient, Mr. Johnson, presented with symptoms\n",
    "of increased thirst, frequent urination, fatigue, and unexplained\n",
    "weight loss. Upon evaluation, he was diagnosed with diabetes,\n",
    "confirmed by elevated blood sugar levels. Mr. Johnson's weight\n",
    "is 210 lbs. He has been prescribed Metformin to be taken twice daily\n",
    "with meals. It was noted during the consultation that the patient is\n",
    "a current smoker. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Extract information from the following medical notes:\n",
    "{medical_notes}\n",
    "\n",
    "Return json format with the following JSON schema: \n",
    "\n",
    "{{\n",
    "        \"age\": {{\n",
    "            \"type\": \"integer\"\n",
    "        }},\n",
    "        \"gender\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"male\", \"female\", \"other\"]\n",
    "        }},\n",
    "        \"diagnosis\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"migraine\", \"diabetes\", \"arthritis\", \"acne\"]\n",
    "        }},\n",
    "        \"weight\": {{\n",
    "            \"type\": \"integer\"\n",
    "        }},\n",
    "        \"smoking\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"yes\", \"no\"]\n",
    "        }}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"age\": 60, \"gender\": \"male\", \"diagnosis\": \"diabetes\", \"weight\": 210, \"smoking\": \"yes\"}\n"
     ]
    }
   ],
   "source": [
    "response = mistral(prompt, is_json=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "Dear mortgage lender, \n",
    "\n",
    "What's your 30-year fixed-rate APR, how is it compared to the 15-year \n",
    "fixed rate?\n",
    "\n",
    "Regards,\n",
    "Anna\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "\n",
    "You are a mortgage lender customer service bot, and your task is to \n",
    "create personalized email responses to address customer questions.\n",
    "Answer the customer's inquiry using the provided facts below. Ensure \n",
    "that your response is clear, concise, and directly addresses the \n",
    "customer's question. Address the customer in a friendly and \n",
    "professional manner. Sign the email with \"Lender Customer Support.\"   \n",
    "      \n",
    "# Facts\n",
    "30-year fixed-rate: interest rate 6.403%, APR 6.484%\n",
    "20-year fixed-rate: interest rate 6.329%, APR 6.429%\n",
    "15-year fixed-rate: interest rate 5.705%, APR 5.848%\n",
    "10-year fixed-rate: interest rate 5.500%, APR 5.720%\n",
    "7-year ARM: interest rate 7.011%, APR 7.660%\n",
    "5-year ARM: interest rate 6.880%, APR 7.754%\n",
    "3-year ARM: interest rate 6.125%, APR 7.204%\n",
    "30-year fixed-rate FHA: interest rate 5.527%, APR 6.316%\n",
    "30-year fixed-rate VA: interest rate 5.684%, APR 6.062%\n",
    "\n",
    "# Email\n",
    "{email}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Re: Mortgage Interest Rates Inquiry\n",
      "\n",
      "Dear Anna,\n",
      "\n",
      "Thank you for reaching out to us regarding our mortgage rates. I'm happy to provide you with the information you're looking for.\n",
      "\n",
      "Our 30-year fixed-rate mortgage has an APR of 6.484%. In comparison, our 15-year fixed-rate mortgage has a lower APR of 5.848%. This means that while the interest rate for the 15-year term is lower, the overall cost of borrowing, including fees and charges, is also lower when compared to the 30-year term.\n",
      "\n",
      "I hope this information helps you make an informed decision about your mortgage options. If you have any further questions or need clarification on anything, please don't hesitate to ask.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Lender Customer Support\n"
     ]
    }
   ],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletter = \"\"\"\n",
    "European AI champion Mistral AI unveiled new large language models and formed an alliance with Microsoft. \n",
    "\n",
    "What’s new: Mao9istral AI introduced two closed models, Mistral Large and Mistral Small (joining Mistral Medium, which debuted quietly late last year). Microsoft invested $16.3 million in the French startup, and it agreed to distribute Mistral Large on its Azure platform and let Mistral AI use Azure computing infrastructure. Mistral AI makes the new models available to try for free here and to use on its La Plateforme and via custom deployments.\n",
    "\n",
    "Model specs: The new models’ parameter counts, architectures, and training methods are undisclosed. Like the earlier, open source Mistral 7B and Mixtral 8x7B, they can process 32,000 tokens of input context. \n",
    "\n",
    "Mistral Large achieved 81.2 percent on the MMLU benchmark, outperforming Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B, though falling short of GPT-4. Mistral Small, which is optimized for latency and cost, achieved 72.2 percent on MMLU.\n",
    "Both models are fluent in French, German, Spanish, and Italian. They’re trained for function calling and JSON-format output.\n",
    "Microsoft’s investment in Mistral AI is significant but tiny compared to its $13 billion stake in OpenAI and Google and Amazon’s investments in Anthropic, which amount to $2 billion and $4 billion respectively.\n",
    "Mistral AI and Microsoft will collaborate to train bespoke models for customers including European governments.\n",
    "Behind the news: Mistral AI was founded in early 2023 by engineers from Google and Meta. The French government has touted the company as a home-grown competitor to U.S.-based leaders like OpenAI. France’s representatives in the European Commission argued on Mistral’s behalf to loosen the European Union’s AI Act oversight on powerful AI models. \n",
    "\n",
    "Yes, but: Mistral AI’s partnership with Microsoft has divided European lawmakers and regulators. The European Commission, which already was investigating Microsoft’s agreement with OpenAI for potential breaches of antitrust law, plans to investigate the new partnership as well. Members of President Emmanuel Macron’s Renaissance party criticized the deal’s potential to give a U.S. company access to European users’ data. However, other French lawmakers support the relationship.\n",
    "\n",
    "Why it matters: The partnership between Mistral AI and Microsoft gives the startup crucial processing power for training large models and greater access to potential customers around the world. It gives the tech giant greater access to the European market. And it gives Azure customers access to a high-performance model that’s tailored to Europe’s unique regulatory environment.\n",
    "\n",
    "We’re thinking: Mistral AI has made impressive progress in a short time, especially relative to the resources at its disposal as a startup. Its partnership with a leading hyperscaler is a sign of the tremendous processing and distribution power that remains concentrated in the large, U.S.-headquartered cloud companies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a commentator. Your task is to write a report on a newsletter. \n",
    "When presented with the newsletter, come up with interesting questions to ask,\n",
    "and answer each question. \n",
    "Afterward, combine all the information and write a report in the markdown\n",
    "format. \n",
    "\n",
    "# Newsletter: \n",
    "{newsletter}\n",
    "\n",
    "# Instructions: \n",
    "## Summarize:\n",
    "In clear and concise language, summarize the key points and themes \n",
    "presented in the newsletter.\n",
    "\n",
    "## Interesting Questions: \n",
    "Generate three distinct and thought-provoking questions that can be \n",
    "asked about the content of the newsletter. For each question:\n",
    "- After \"Q: \", describe the problem \n",
    "- After \"A: \", provide a detailed explanation of the problem addressed \n",
    "in the question.\n",
    "- Enclose the ultimate answer in <>.\n",
    "\n",
    "## Write a analysis report\n",
    "Using the summary and the answers to the interesting questions, \n",
    "create a comprehensive report in Markdown format. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Summary\n",
      "\n",
      "European AI startup, Mistral AI, has unveiled two new large language models, Mistral Large and Mistral Small, which have outperformed several models from Anthropic, Google, and Meta on the MMLU benchmark. Microsoft has invested $16.3 million in Mistral AI and will distribute Mistral Large on its Azure platform, while Mistral AI will use Azure's computing infrastructure. The partnership has sparked debate among European lawmakers due to potential data access and antitrust concerns.\n",
      "\n",
      "# Interesting Questions\n",
      "\n",
      "## Q: What are the performance metrics of Mistral Large and Mistral Small on the MMLU benchmark?\n",
      "\n",
      "A: Mistral Large achieved 81.2 percent on the MMLU benchmark, surpassing models like Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B, but falling short of GPT-4. Mistral Small, optimized for latency and cost, achieved 72.2 percent on the MMLU benchmark. Both models are fluent in French, German, Spanish, and Italian.\n",
      "\n",
      "## Q: What are the potential implications of the partnership between Mistral AI and Microsoft for European lawmakers and regulators?\n",
      "\n",
      "A: The partnership has divided European lawmakers and regulators. Some have criticized the deal for potentially giving a U.S. company access to European users’ data, while others support the relationship. The European Commission plans to investigate the partnership for potential breaches of antitrust law.\n",
      "\n",
      "## Q: What benefits does the partnership between Mistral AI and Microsoft bring to each party and to Azure customers?\n",
      "\n",
      "A: The partnership provides Mistral AI with crucial processing power for training large models and greater access to potential customers worldwide. Microsoft gains greater access to the European market. Azure customers now have access to a high-performance model tailored to Europe’s unique regulatory environment.\n",
      "\n",
      "# Analysis Report\n",
      "\n",
      "Mistral AI, a European AI startup, has made significant strides in the AI landscape with the introduction of two new large language models, Mistral Large and Mistral Small. These models have demonstrated impressive performance on the MMLU benchmark, outperforming several models from major tech companies.\n",
      "\n",
      "This achievement has been bolstered by a strategic partnership with Microsoft, which has invested $16.3 million in Mistral AI. This investment is a drop in the ocean compared to Microsoft's $13 billion stake in OpenAI or Google and Amazon's investments in Anthropic, but it is a crucial step for Mistral AI. The partnership allows Mistral AI to leverage Microsoft's Azure platform for distribution and its computing infrastructure for training, providing the startup with the processing power it needs to compete with larger players.\n",
      "\n",
      "However, the partnership has not been without controversy. European lawmakers and regulators have expressed concerns about potential data access and antitrust issues. The European Commission, already investigating Microsoft's agreement with OpenAI, plans to investigate the new partnership as well. This divide among European lawmakers reflects the broader debate about the role of U.S. tech companies in Europe and the need to protect European data and interests.\n",
      "\n",
      "Despite these challenges, the partnership between Mistral AI and Microsoft brings significant benefits to all parties involved. Mistral AI gains the resources it needs to compete on a global scale, Microsoft expands its reach in the European market, and Azure customers gain access to a high-performance model tailored to Europe’s unique regulatory environment.\n",
      "\n",
      "In conclusion, Mistral AI's rapid progress and partnership with Microsoft highlight the ongoing concentration of processing and distribution power in large, U.S.-headquartered cloud companies. However, it also demonstrates the potential for European startups to compete in this landscape, given the right resources and partnerships.\n"
     ]
    }
   ],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Classify the following email to determine if it is spam or not.\n",
    "Only respond with the exact text \"Spam\" or \"Not Spam\". \n",
    "\n",
    "# Email:\n",
    "🎉 Urgent! You've Won a $1,000,000 Cash Prize! \n",
    "💰 To claim your prize, please click on the link below: \n",
    "https://bit.ly/claim-your-prize\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spam'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral(prompt, model=\"mistral-small-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Compose a welcome email for new customers who have just made \n",
    "their first purchase with your product. \n",
    "Start by expressing your gratitude for their business, \n",
    "and then convey your excitement for having them as a customer. \n",
    "Include relevant details about their recent order. \n",
    "Sign the email with \"The Fun Shop Team\".\n",
    "\n",
    "Order details:\n",
    "- Customer name: Anna\n",
    "- Product: hat \n",
    "- Estimate date of delivery: Feb. 25, 2024\n",
    "- Return policy: 30 days\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_medium = mistral(prompt, model=\"mistral-medium-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Welcome to The Fun Shop, Anna! Your Hat is on its Way!\n",
      "\n",
      "Dear Anna,\n",
      "\n",
      "We are beyond thrilled to welcome you to The Fun Shop family! We want to express our heartfelt gratitude for your decision to make your first purchase with us. Your support means the world to us!\n",
      "\n",
      "We hope you're as excited as we are about your new hat! Our team has been working hard to ensure that your order is processed and shipped as quickly as possible. According to our records, your hat is expected to arrive at your doorstep on February 25, 2024. We will keep you updated on the status of your order and will let you know as soon as it's shipped.\n",
      "\n",
      "We want you to be completely satisfied with your purchase, so if for any reason you're not happy with your hat, please don't hesitate to reach out to us. We offer a 30-day return policy, so you have plenty of time to decide if it's the right fit for you.\n",
      "\n",
      "Thank you once again for choosing The Fun Shop for your shopping needs. We're committed to providing you with the best possible experience and are always here to help. If you have any questions or concerns, please don't hesitate to contact us at [support@thefunshop.com](mailto:support@thefunshop.com).\n",
      "\n",
      "Best regards,\n",
      "\n",
      "The Fun Shop Team\n"
     ]
    }
   ],
   "source": [
    "print(response_medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Calculate the difference in payment dates between the two \\\n",
    "customers whose payment amounts are closest to each other \\\n",
    "in the following dataset. Do not write code.\n",
    "\n",
    "# dataset: \n",
    "'{\n",
    "  \"transaction_id\":{\"0\":\"T1001\",\"1\":\"T1002\",\"2\":\"T1003\",\"3\":\"T1004\",\"4\":\"T1005\"},\n",
    "    \"customer_id\":{\"0\":\"C001\",\"1\":\"C002\",\"2\":\"C003\",\"3\":\"C002\",\"4\":\"C001\"},\n",
    "    \"payment_amount\":{\"0\":125.5,\"1\":89.99,\"2\":120.0,\"3\":54.3,\"4\":210.2},\n",
    "\"payment_date\":{\"0\":\"2021-10-05\",\"1\":\"2021-10-06\",\"2\":\"2021-10-07\",\"3\":\"2021-10-05\",\"4\":\"2021-10-08\"},\n",
    "    \"payment_status\":{\"0\":\"Paid\",\"1\":\"Unpaid\",\"2\":\"Paid\",\"3\":\"Paid\",\"4\":\"Pending\"}\n",
    "}'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_small = mistral(prompt, model=\"mistral-small-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this, we first need to identify the two customers with the closest payment amounts. From the dataset, we can see that C001 and C003 have the closest payment amounts (125.5 and 120.0).\n",
      "\n",
      "Next, we need to find the difference in payment dates between these two customers. C001 made a payment on 2021-10-05 and C003 made a payment on 2021-10-07.\n",
      "\n",
      "So, the difference in payment dates between C001 and C003 is 2 days.\n"
     ]
    }
   ],
   "source": [
    "print(response_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_large = mistral(prompt, model=\"mistral-large-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the difference in payment dates between the two customers whose payment amounts are closest to each other, we first need to identify the two closest payment amounts.\n",
      "\n",
      "In the provided dataset, the payment amounts are as follows:\n",
      "\n",
      "- T1001: $125.50\n",
      "- T1002: $89.99\n",
      "- T1003: $120.00\n",
      "- T1004: $54.30\n",
      "- T1005: $210.20\n",
      "\n",
      "The two closest payment amounts are $125.50 and $120.00, with a difference of $5.50. These amounts correspond to transactions T1001 and T1003, made by customers C001 and C003, respectively.\n",
      "\n",
      "Now, let's find the difference in payment dates:\n",
      "\n",
      "- T1001 was made on 2021-10-05.\n",
      "- T1003 was made on 2021-10-07.\n",
      "\n",
      "To calculate the difference between these two dates:\n",
      "\n",
      "- Subtract the earlier date (2021-10-05) from the later date (2021-10-07).\n",
      "\n",
      "The difference in payment dates between the two customers whose payment amounts are closest to each other is 2 days.\n"
     ]
    }
   ],
   "source": [
    "print(response_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expense "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-llm-env",
   "language": "python",
   "name": "my-llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Appetizers:\n",
      "1. Hyderabadi Chicken Tikka Skewers\n",
      "2. Mirchi Bajji (Stuffed Green Chilies)\n",
      "3. Kebab Platter (Assortment of chicken, lamb, and beef kebabs)\n",
      "4. Prawn Fry\n",
      "5. Veg Samosas\n",
      "6. Dahi Papdi Chaat (Savory yogurt and crispy chips)\n",
      "7. Tandoori Gobi (Cauliflower marinated in Indian spices)\n",
      "8. Mutton Haleem (Slow-cooked lentil and meat stew)\n",
      "9. Dumplings (Choice of chicken, vegetable, or paneer)\n",
      "10. Aloo Tikki (Potato patties served with chutney)\n",
      "\n",
      "Soups:\n",
      "11. Hyderabadi Shorba (Spiced lentil soup)\n",
      "12. Tomato Rasam (Tangy tomato soup with traditional spices)\n",
      "13. Paya Shorba (Slow-cooked goat trotters soup)\n",
      "\n",
      "Main Dishes:\n",
      "14. Hyderabadi Biryani (Choice of chicken, lamb, or vegetable)\n",
      "15. Haleem (Meat and lentil stew served with bread)\n",
      "16. Butter Chicken (Tandoori chicken in a creamy tomato sauce)\n",
      "17. Nizami\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(temperature=0.9)\n",
    "hotelMenu = llm.invoke(\"I want to open a restaurant in Hyderabad. Suggest Menu.\")\n",
    "print(hotelMenu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config',\n",
       " 'Music',\n",
       " '.condarc',\n",
       " '.DS_Store',\n",
       " 'get-pip.py',\n",
       " 'requirements.txt',\n",
       " '.CFUserTextEncoding',\n",
       " '.xonshrc',\n",
       " '.zshrc',\n",
       " 'Pictures',\n",
       " 'mlflow',\n",
       " '.zsh_history',\n",
       " '.ipython',\n",
       " 'Desktop',\n",
       " 'Library',\n",
       " '.vpn',\n",
       " '.matplotlib',\n",
       " 'gensim-data',\n",
       " '.cups',\n",
       " 'PycharmProjects',\n",
       " 'Public',\n",
       " '.tcshrc',\n",
       " '.cisco',\n",
       " '.anaconda',\n",
       " 'Movies',\n",
       " 'Applications',\n",
       " 'my-llm-env',\n",
       " '.Trash',\n",
       " '.ipynb_checkpoints',\n",
       " 'LLM-Projects',\n",
       " '.jupyter',\n",
       " '.vmware',\n",
       " 'Documents',\n",
       " '.vscode',\n",
       " '.bash_profile',\n",
       " 'anaconda3',\n",
       " 'Downloads',\n",
       " '.continuum',\n",
       " '.cache',\n",
       " '.aws',\n",
       " '.gitconfig',\n",
       " '.viminfo',\n",
       " '.zsh_sessions',\n",
       " '.conda',\n",
       " '.idea',\n",
       " 'miniconda3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"/Users/lrao9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File klnsuman/LangChain/data/eBook-How-to-Build-a-Career-in-AI.pdf does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDirectoryReader\n\u001b[0;32m----> 2\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleDirectoryReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mklnsuman/LangChain/data/eBook-How-to-Build-a-Career-in-AI.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[0;32m~/my-llm-env/lib/python3.11/site-packages/llama_index/readers/file/base.py:141\u001b[0m, in \u001b[0;36mSimpleDirectoryReader.__init__\u001b[0;34m(self, input_dir, input_files, exclude, exclude_hidden, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m input_files:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(path):\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m     input_file \u001b[38;5;241m=\u001b[39m Path(path)\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_files\u001b[38;5;241m.\u001b[39mappend(input_file)\n",
      "\u001b[0;31mValueError\u001b[0m: File klnsuman/LangChain/data/eBook-How-to-Build-a-Career-in-AI.pdf does not exist."
     ]
    }
   ],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"klnsuman/LangChain/data/eBook-How-to-Build-a-Career-in-AI.pdf\"] data/eBook-How-to-Build-a-Career-in-AI.pdf\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "41 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: 20a8a591-db0a-4c83-a603-f8e88661d18f\n",
      "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
      "How to  Build Your Career in AIA Simple Guide\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9.8\n"
     ]
    }
   ],
   "source": [
    "import llama_index\n",
    "print(llama_index.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84c14114a2c468fae381028231bb3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42860891eb9b40ac8f1a3a84ed6255a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae28b2e1990471b8e1ccecf7bd15dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c3c534a55d4a24a6709a0f05deec36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6150788fc2ed439bb6bce234e6d3d732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0194c6fe0a71450981502d03261678c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "index = VectorStoreIndex.from_documents([document],\n",
    "                                        service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When finding projects to build your experience, there are several steps you can take. First, you can join existing projects by asking to join someone else's project if they have an idea. Additionally, you can continue reading, taking courses, and talking to domain experts to come up with new ideas. It is also helpful to focus on an application area that has not yet been explored with machine learning. If your company or school has a particular application in mind, you can explore the possibilities for machine learning in that area. Finally, you can develop a side hustle or personal project that may not initially be part of your job but can help you gain experience and strengthen your skills.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are steps to take when finding projects to build your experience?\"\n",
    ")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

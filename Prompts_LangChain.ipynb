{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QOIftHRcLMOk34U5k3IGn_cPDgr3oDhX",
      "authorship_tag": "ABX9TyNJ4nby7Jhw1IUIdH+d55Fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klnsuman/LangChain/blob/main/Prompts_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOEuECvko8YU",
        "outputId": "cba72cd4-aa21-426a-eccd-af69a37b9a3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "OpenAI API Key:··········\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/colab_env/lib/python3.10/site-packages\")\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install virtualenv"
      ],
      "metadata": {
        "id": "LNoToWJmbVmb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!virtualenv /content/drive/MyDrive/colab_env\n",
        "#!source /content/drive/MyDrive/colab_env/bin/activate; pip install langchain\n",
        "#!source /content/drive/MyDrive/colab_env/bin/activate; pip install chromadb openai tiktoken faiss-cpu"
      ],
      "metadata": {
        "id": "BHzVf8G1bEXK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Prompts***"
      ],
      "metadata": {
        "id": "uBycDyKTvkEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "prompt = \"\"\"\n",
        "Today is Monday tomorrow is saturday\n",
        "\n",
        "what is wrong with statement?\n",
        "\"\"\"\n",
        "\n",
        "llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cPx2ltTXpb3U",
        "outputId": "cc0a9497-fdd5-489e-907d-704ec919ab19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe statement is incorrect because Monday and Saturday are not consecutive days of the week.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "prompt = \"\"\"\n",
        "What is capital of India\n",
        "\"\"\"\n",
        "print(llm(prompt))\n",
        "\n",
        "prompt = \"\"\"\n",
        "How much is 2 greater than 1\n",
        "\"\"\"\n",
        "print(llm(prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kemZp3od6qlo",
        "outputId": "b7772d42-cfe9-49dc-bc83-ffc0d51e4406"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-BOZahmnqnXW77ACkkAlSZCsy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The capital of India is New Delhi.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-BOZahmnqnXW77ACkkAlSZCsy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-BOZahmnqnXW77ACkkAlSZCsy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-BOZahmnqnXW77ACkkAlSZCsy on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2 is 1 greater than 1, so the answer is 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "How long does Tortoise Live\n",
        "\"\"\"\n",
        "\n",
        "llm(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tCC36GUTAv7X",
        "outputId": "5fc05693-5d66-424c-a583-d3560a94427e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTortoises can live for up to 150 years or more, depending on the species. Some species of tortoise, such as the giant Galapagos tortoise, can live for over 200 years.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Prompt Templates***"
      ],
      "metadata": {
        "id": "ATXlg7CQvYeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = \" What is the capital city of {country}\"\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "\n",
        "prompt = PromptTemplate(input_variables = [\"country\"],template=prompt_template)\n",
        "\n",
        "final_prompt = prompt.format(country='India')\n",
        "print(final_prompt)\n",
        "print(llm(final_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKmAz49irypH",
        "outputId": "470a77c3-44ac-418c-dc2e-249f7fc207a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " What is the capital city of India\n",
            "?\n",
            "\n",
            "The capital city of India is New Delhi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Example Selectors***"
      ],
      "metadata": {
        "id": "lbH4-wbrvWNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import FewShotPromptWithTemplates,FewShotPromptTemplate,PromptTemplate\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "Ia6tu81TtfkT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Example Input: {input}\\nExample Output: {output}\",\n",
        ")\n",
        "\n",
        "# Examples of locations that nouns are found\n",
        "examples = [\n",
        "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
        "    {\"input\": \"pilot\", \"output\": \"plane\"},\n",
        "    {\"input\": \"driver\", \"output\": \"car\"},\n",
        "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
        "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
        "]"
      ],
      "metadata": {
        "id": "3WBAI4fmD10R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SemanticSimilarityExampleSelector will select examples that are similar to your input by semantic meaning\n",
        "\n",
        "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    # This is the list of examples available to select from.\n",
        "    examples,\n",
        "\n",
        "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
        "    OpenAIEmbeddings(),\n",
        "\n",
        "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
        "    FAISS,\n",
        "\n",
        "    # This is the number of examples to produce.\n",
        "    k=2\n",
        ")"
      ],
      "metadata": {
        "id": "Ayo-lvS0JrLk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_prompt = FewShotPromptTemplate(\n",
        "    # The object that will help select examples\n",
        "    example_selector=example_selector,\n",
        "\n",
        "    # Your prompt\n",
        "    example_prompt=example_prompt,\n",
        "\n",
        "    # Customizations that will be added to the top and bottom of your prompt\n",
        "    prefix=\"Give the location an item is usually found in\",\n",
        "    suffix=\"Input: {noun}\\nOutput:\",\n",
        "\n",
        "    # What inputs your prompt will receive\n",
        "    input_variables=[\"noun\"],\n",
        ")\n"
      ],
      "metadata": {
        "id": "U1lYXGSxcizV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a noun!\n",
        "my_noun = \"student\"\n",
        "\n",
        "print(similar_prompt.format(noun=my_noun))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew238BEMc9pN",
        "outputId": "adc6ddda-78ab-434d-c3c3-5261f726a8cb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Give the location an item is usually found in\n",
            "\n",
            "Example Input: driver\n",
            "Example Output: car\n",
            "\n",
            "Example Input: pilot\n",
            "Example Output: plane\n",
            "\n",
            "Input: student\n",
            "Output:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(similar_prompt.format(noun=my_noun))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tu1kQ8PxdEc8",
        "outputId": "00faa30a-d27b-4d98-fedb-1dc349839c86"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' classroom'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OUTPUT Parser**"
      ],
      "metadata": {
        "id": "bq6BvfkxfC3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "nRNFcZqxfCb2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name=\"text-davinci-003\")"
      ],
      "metadata": {
        "id": "ksDUrSlwdJoI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How you would like your response structured. This is basically a fancy prompt template\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
        "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
        "]\n",
        "\n",
        "# How you would like to parse your output\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ],
      "metadata": {
        "id": "wNfZQRn6fXvU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the prompt template you created for formatting\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "print (format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpqsG60Zfay9",
        "outputId": "a39f5554-ef00-4cb2-a891-7dbaeff32a6f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"bad_string\": string  // This a poorly formatted user input string\n",
            "\t\"good_string\": string  // This is your response, a reformatted response\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You will be given a poorly formatted string from a user.\n",
        "Reformat it and make sure all the words are spelled correctly\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "% USER INPUT:\n",
        "{user_input}\n",
        "\n",
        "YOUR RESPONSE:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"user_input\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        "    template=template\n",
        ")\n",
        "\n",
        "promptValue = prompt.format(user_input=\"yelcom to Hyd!\")\n",
        "\n",
        "print(promptValue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at1cRTZXffP4",
        "outputId": "86921452-e2c3-489c-e675-606db46756ba"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You will be given a poorly formatted string from a user.\n",
            "Reformat it and make sure all the words are spelled correctly\n",
            "\n",
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"bad_string\": string  // This a poorly formatted user input string\n",
            "\t\"good_string\": string  // This is your response, a reformatted response\n",
            "}\n",
            "```\n",
            "\n",
            "% USER INPUT:\n",
            "yelcom to Hyd!\n",
            "\n",
            "YOUR RESPONSE:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_output = llm(promptValue)\n",
        "llm_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KBw9SeQrfiZJ",
        "outputId": "836bdbea-5d73-4117-cd18-97fa1fd7ab91"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```json\\n{\\n\\t\"bad_string\": \"yelcom to Hyd!\",\\n\\t\"good_string\": \"Welcome to Hyde!\"\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser.parse(llm_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbWRb7N1flHm",
        "outputId": "63f7ac5e-6442-4fab-ee63-c86d8e5d0463"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bad_string': 'yelcom to Hyd!', 'good_string': 'Welcome to Hyde!'}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ziwRF-qjfnWg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}